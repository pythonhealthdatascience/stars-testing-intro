---
title: "Parameterising tests"
---

```{r}
#| include: false
library(reticulate)
use_condaenv("stars-testing-intro", required = TRUE)
```

{{< include /assets/language-selector.html >}}

<br>

There are many tools you can make use of when testing - one example is **parametrising** tests.

When you need to test the same logic with different inputs and expected outputs, you can parameterise your tests instead of writing repetitive test functions. This minimises code duplication and makes it easy to add new test cases.

## Example: Testing `summary_stats()`

Let's say we want to verify that our `summary_stats()` function works correctly for different datasets. 

:::: {.callout-note title="View `summary_stats()`" collapse="true"}

::: {.python-content}

```{python}
#| file: code/patient_analysis__summary_stats.py
#| eval: false
```

:::

::: {.r-content}

```{r}
#| file: code/patient_analysis__summary_stats.R
#| eval: false
```

:::

::::

::: {.python-content}

We will need the following imports in our test script:

```{python}
#| file: code/test_intro_parametrised__imports.py
#| eval: false
```

Instead of writing separate test functions for each case, we can use pytest's `@pytest.mark.parametrize` decorator:

```{python}
#| file: code/test_intro_parametrised__test_summary_stats.py
#| eval: false
```

## How it works

The `@pytest.mark.parametrize` decorator takes two arguments:

1. **Parameter names** (as a string). These variable names will be passed to your test function. For example:

```
"data, expected_mean, expected_std, expected_ci_lower, expected_ci_upper"
```

2. **Test cases** (as a list of tuples). Each tuple contains values for one test case. For example:

```
[
    # Five value sample with known summary statistics
    ([1.0, 2.0, 3.0, 4.0, 5.0], 3.0, 1.58, 1.04, 4.96),
    # No variation: CI collapse to mean
    ([5, 5, 5], 5, 0, 5, 5),
]
```

If any test case fails, pytest will clearly indicate which parameters were used, making debugging straightforward.

:::

::: {.r-content}

<br>

Instead of `test_that()`, we will use the function `with_parameters_test_that()` from Google's `patrick` package. This lets us write our test code once, then provide a list of input/output combinations (the "cases") that are run through the same test code.

The general pattern is:

```{.r}
patrick::with_parameters_test_that(
  "Description of test",
  {
    # Test code using the parameters e.g., expect_...
  },
  patrick::cases(
    list(input1 = 5L, input2 = 10L, output = 500L),
    list(input1 = 6L, input2 = 11L, output = 600L)
  )
)
```

Each `list()` inside `cases()` defines one test case, with named elements matching the arguments used inside the code block.

<br>

For `summary_stats`, we can write our test as:

```{r}
#| file: code/test_intro_parametrised__summary_stats_returns_expected.R
#| eval: false
```

When this test runs, `with_parameters_test_that()` executes the code block once for each case, substituting in the corresponding data and expected values.

:::

## Running our test

:::: {.callout-note title="Test output"}

::: {.python-content}

```{python}
#| echo: false
import pytest
pytest.main(["../examples/python_package/tests/test_intro_parametrised.py"])
```

:::

::: {.r-content}

```{r}
#| echo: false
#| output: false
devtools::load_all("../examples/r_package")
```

```{r}
#| echo: false
testthat::test_file(
  "../examples/r_package/tests/testthat/test_intro_parametrised.R"
)
```

:::

::::
